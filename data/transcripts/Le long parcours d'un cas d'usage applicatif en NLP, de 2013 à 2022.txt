Voilà, je m'auto-applaudis, donc effectivement, ça va être sur l'explication d'un long parcours vu que c'est pas encore terminé, parce qu'on continue.
Mais bon, un long parcours sur le NLP, sur le NLP applicatif.
Alors juste, parce que je remercie, parce qu'il a oublié de remercier le mojo qui nous accueille.
Et donc là, j'ai juste un petit slide sur la boîte dans lequel je travaille, qui s'appelle l'ISEO.
Donc historiquement, on était une boîte spécialisée dans le pneumatique, on aspire chaque jour plus de 1000 sites internet, on récupère des flux divers et variés, des catalogues, etc.
Plein, plein de choses, et à partir de tout ça, on extrait des informations, que l'on revend soit au site qu'on a aspiré, ce qui est assez sympathique,
et qu'on revend aussi au manufacturier, à des distributeurs, etc.
Donc là, il y a tout un process de travail qui est fait par-ci, un process, ça c'est compliqué, je reviendrai là-dessus après.
Et, comment dirais-je, donc on a démarré dans le pneumatique en 2009, et donc maintenant, on cherche surtout à se diversifier.
Donc là, le dernier truc que j'ai eu, je ne savais même pas qu'on faisait ça, c'était sur les parfums.
Parfum, lubrifiant, camion d'occasion, véhicule d'occasion, élément reconditionné, etc.
C'est vraiment l'axe principal, parce qu'élace, on a pratiquement tous les grands manufacturiers à notre catalogue.
Donc là, le principe, c'est un peu l'histoire, je ne vais pas revenir là-dessus, on a démarré en 2009.
Je vais plutôt zoomer sur, j'avais dit que c'était de 2012-2011, donc c'était en 2013, où il y a eu un petit big bang qui était lié au phénomène de récupération d'informations sur les réseaux sociaux.
Donc des éléments qui changeaient un petit peu notre point de vue, vu que là, ce n'est pas du tout la même chose d'extraire de l'information
sur des données que je qualifierais de semi-structurés comme des pages HTML ou des catalogues, etc.
Là, on récupérait plus de 1200 blogs sur le pneumatique.
Donc il y a des malades mentales qui parlent du pneu, on a des trucs spécialisés, donc c'est bon, sur Facebook, sur Twitter, plein de trucs comme ça en fait.
Et ça, ce n'est pas du tout la même chose.
C'est moins structuré et surtout, ça parle dans 20 ans de choses qui n'ont rien à voir avec, je dirais, le titre du blog d'autres éléments.
Donc c'est vraiment 2013 qui va nous intéresser et c'est à partir de 2013 où on a travaillé sur cet aspect NLP.
Donc, oui, je n'ai pas traduit NLP, je pense que tout le monde sait, c'est une naturelle language processing, donc extraction d'informations à partir de textes bruts.
Voilà, donc dernière petite chose, c'est simplement pour dire sur quel niveau on se positionne.
Donc là, c'est tout le processus que l'on suit, donc on est comme une grosse usine en fait.
D'ailleurs, une partie de la société s'appelle Data Factory, c'est l'usine.
Donc ça démarre la mine, voilà.
Donc en gros, on extrait des informations à partir d'internet et plein de flux.
Donc là, nos activités de R&D, qu'est-ce qu'on a fait là-dessus ?
C'est un peu la course à l'armement pour extraire des choses et pour scraper des sites.
Vous savez, il y a des gens qui se protègent, qui ne veulent pas être aspirés, etc.
C'est normal.
Donc après, nous, on essaye de faire en sorte de passer outre ces protections, ces CAPTCHA, ces machins, etc.
Enfin, tous les trucs, divers et variés.
Donc, temps en temps, on a fait tout un système pour faire en sorte qu'on naviguait comme un humain.
Pour que ça soit aussi lent qu'un humain, avec les mêmes erreurs qu'un humain et qu'on ait une vision comme un humain.
Bon, ça, c'est anecdotique.
Ensuite, c'est vraiment la partie extraction automatique de données.
Donc il y a des éléments au niveau de l'extraction de données semi-structurées ou structurées.
Ce n'est pas ce qui nous intéresse.
Ce qui va nous intéresser aujourd'hui, c'est vraiment la partie extraction à partir de textes brut.
Et de textes écrits dans un langage un peu divers et variés.
Là aussi, l'extraction qu'on a, l'application qu'on a réalisée, c'est sur six langues.
Donc il y a aussi l'aspect multilangue qui était intéressante.
Puis, il y a une petite chose aussi, découverte de thématiques.
Là, on travaille aussi justement pour faire la big picture qu'on avait prévue, peut-être pas en 2013,
mais qu'on avait prévue ces dernières années.
C'est de dire, on va extraire aussi les thématiques d'une manière automatique.
Ensuite, il y a la partie matching, donc le fait qu'on aspire des choses, etc.
À l'intérieur, on trouve ce qu'on appelle des entités nommées,
soit une marque, soit le nom d'un produit, soit des caractéristiques, etc.
Et l'objectif du matching, c'est de dire, un même produit peut apparaître sur plein de sources différentes
avec une présentation, une désignation différente.
Donc tout le matching, c'est de dire, je vais fabriquer un référentiel
où, chaque fois que je vois un produit qui a peut-être des variations de nom,
parce que pour des raisons X, Y, Z, le site a réduit le nom, a compacté, a fait des tas de choses,
non, c'est la même chose.
Donc, même chose, si le site, il s'est planté dans le...
produit n'existe pas, en fait.
Et globalement, dans le monde du pneumatique, 20% de ce qu'on scrapait n'existaient pas,
en fait, que le vrai produit, enfin, produit avec toutes les informations nécessaires,
ben là aussi, il ne faut pas le créer, etc.
Donc là, la partie matching.
Et ensuite, il y a d'autres éléments qu'on a pu réaliser en R&D,
la détection automatique de points aberrants, des prix aberrants,
alors un petit peu plus subtiles que simplement des corridors.
La comparaison automatique de produit, de dire, je sélectionne un produit,
hop, c'est quoi, automatiquement, tous les produits comparables.
Alors, sachant que, dans le monde du pneumatique,
il y a 450 marques de produits différents,
on ne se rend pas compte, comme ça,
et il y a, je crois, je crois que dans notre base, on a 600 000 pneus différents.
Donc, ça fait beaucoup, beaucoup de produits.
Donc, c'est difficile de les comparer les uns par rapport aux autres.
Donc, c'est intéressant de faire un système automatique de comparaison.
Et puis ensuite, on fait aussi de l'analyse prédictive, etc.,
enfin, des analyses par rapport à tous ces flux de nuit.
Mais ce qui nous intéresse aujourd'hui, c'est cette partie-là.
Alors, je ne me suis pas présenté, donc je m'appelle Bruno Canizia,
et je suis le responsable de la R&D au sein de la société.
Alors, R&D, très souvent, les gens ne voient surtout le D.
Voilà.
Nous, on fait aussi du R.
Donc, c'est pour ça qu'on a beaucoup fait de thèses intégrées en entreprise,
des thèses cifres.
On a eu trois thèses.
Donc, une dernière qui va se positionner, enfin, qui va être soutenue,
en espérant Mars de cette année.
Donc, des thèses sur différents apprentissages multilabels,
annotations thématiques, justement, pour les données,
la modélisation de thématiques, etc.
Et on publie.
Donc, l'objectif, c'est de publier aussi.
Donc, vous pouvez récupérer ou chercher des éléments à Cliseo.
Il y a 24 publications scientifiques qu'on a fait depuis 2014, en fait,
sur plein de sujets divers et variés.
Donc, l'objectif, vraiment, c'est de la vraie R&D.
Enfin, on va dire que c'est de la vraie R,
et qu'on applique vraiment à la partie développement chaînement.
Bien, indépendamment de tout ça, le cas d'usage de la qualification.
Donc, le projet a été lancé en 2012-2013.
Alors, c'était un peu sous l'influence d'un client qui nous a demandé ça.
Bon, je ne dirais pas le nom du client.
Donc, cette vision-là, c'était, comment dirais-je,
de suivre, finalement, ce que ressentent,
ce que notent les différents consommateurs au niveau des produits.
Ça peut être la marque, le produit, etc.
Suivant différentes caractéristiques de performances qui sont associées.
Donc, qu'est-ce que ça veut dire ?
La qualification, c'est de dire, voilà, j'ai une phrase,
et je peux exprimer, ça parle de tels sujets, tels sujets,
sur telle entité nommée, etc.
Et c'est plutôt positif ou négatif.
Alors, on est écrins de la seule magique formule que je mettrai dans la présentation.
Ce n'est pas une magique formule,
c'est simplement pour revenir vraiment à ce que c'est
que la notion, je dirais, d'opinion, en fait.
La vraie analyse d'opinion précise.
L'analyse d'opinion, c'est arriver dans un texte
à repérer une entité nommée.
Donc, un objet, quelque chose qu'on suit.
Ensuite, par rapport au texte qui est derrière,
c'est quoi la propriété dont parle l'internaute
ou le texte sur cette entité nommée.
Et ensuite, cette propriété, donc, fonctionnalité, propriété,
si jamais c'était, je ne sais pas, un iPhone,
c'est, je ne sais pas, ça dure et de vie,
son rapport qualité-pris, son autonomie, etc., etc.
Qualité d'écran, voilà, plein de propriété.
Donc, c'est ça.
Et là, l'internaute est-ce qu'il est plutôt positif
ou négatif par rapport à ça.
Donc, la vraie notion, c'est ça.
Il faut repérer l'entité, définir la qualification,
la propriété et noter cette propriété.
Donc, ce n'est pas un truc pour dire,
globalement, le texte est positif, négatif,
ça, ça ne veut rien dire.
Enfin, ça n'a aucun intérêt
pour une vraie réalité applicative dans une entreprise.
Pour vraiment dire, oui, c'est positif,
ce même produit peut-être positif pour une propriété
et négatif pour une autre.
Donc, c'est vraiment le cœur du système.
Voilà.
Donc, bon, là, il y a un petit dessin,
mais un petit exemple, c'est mieux.
Voilà.
Donc, l'objectif, c'est de se dire,
j'ai cette phrase.
Bon, j'ai roulé sous la pluie
dans un 408 break avec les énergies serveurs,
17 pouces, c'est super.
Donc, l'objectif là-dedans, c'est de dire,
je repère l'entité énergie serveur,
c'est un pneu, un produit Michelin.
Donc, nous, on a tout un référentiel.
Donc, on va dire que c'est facile pour nous
de repérer les entités nommées,
vu qu'on a un référentiel bien construit.
Donc, grâce à ça, on sait que c'est énergie serveur
qui appartient à la gamme d'énergie,
qui appartient à Michelin.
Voilà.
Pas de problème.
Bon, après, ça s'est fait,
s'il est énergie serveur,
après, ça peut s'apparaître
énerg-save, truc-muche, e-save, etc.
J'ai roulé sous la pluie.
Donc, j'ai roulé sous la pluie.
Là, on avait défini plein de propriétés
que le client aimerait suivre.
On a discuté avec le client.
C'est quoi les propriétés
qui vous intéressent
quand vous analysez, effectivement,
quelque chose au niveau de votre produit.
Bah là, c'est la traction sur le sol humide.
Donc, il faut traduire ça
dans une vision.
C'est une propriété,
traction sur le sol humide.
Donc, c'est ça la fonctionnalité
que je vais accrocher
à l'entité numérique.
Et c'est super.
Bah, a priori, c'est plutôt positif.
Voilà.
Tout le cœur du système,
tout l'objectif,
ça a été de fabriquer un système
qui peut extraire automatiquement ça.
Alors, c'est beau sur le papier.
Donc, ça, c'était en 2013.
On se disait, c'est génial, super idée.
Et l'objectif derrière,
c'est de sortir ce genre d'analyse.
Bon, là, c'est deux-trois extraits
qu'on a fait, bon, c'est ça.
Globalement, pour dire,
bah voilà, les analyses,
les opinions positives, négatives,
par rapport aux différentes propriétés
qu'on peut avoir.
Ensuite, les opinions pénitives
regroupées par marque, etc.
Pour se dire, bah voilà,
en fonction des sujets,
même chose, là,
c'est de la même vision,
mais cette fois-ci, toujours un regroupement,
mais par rapport à différents produits.
Donc, par rapport à la vision,
durée de vie, sécurité, le look,
comment dirais-je,
l'économie d'énergie,
voilà, la satisfaction, etc.
Donc, plein de choses.
Et l'objectif, c'est vraiment comparer
pas d'une vision absolue par rapport à des tests,
mais comparer effectivement les produits,
les imparables aux autres,
vis-à-vis de toutes les propriétés
et tous les retours, finalement,
consommateurs qu'on n'a plus récupérés.
Bien !
Alors, maintenant, on a ça,
comment faire ?
Donc, 2013.
Bon, déjà,
2013, on s'est dit, bah,
il n'y a pas de magie,
il faut qu'on fabrique une base d'apprentissage.
Parce que pour arriver à apprendre
comment exprimer une propriété
avec plein de textes divers et variés,
et de mots-clés divers et variés,
plein de choses,
bah, il n'y a qu'une chose,
il faut une base d'apprentissage.
Ensuite, bon,
beaucoup de prêtraitement de données,
de la détection d'entités nommées,
la détection des qualifeurs,
et l'évaluation de la tonalité.
Eh bien, on va suivre
exactement ce petit plan.
Démarrage, création d'une base d'apprentissage.
Alors,
alors, je veux dire,
pourquoi il me parle de la création
d'une base d'apprentissage ?
Bah, c'est tout le problème
de qualification, de tagging, etc.
Quels que soient vos problèmes
que vous ayez,
que ce soit du NLP
ou de la reconnaissance d'image
ou n'importe quoi,
ce qui compte,
c'est la qualité
de votre base d'apprentissage,
ce sur quoi vous allez apprendre
et avoir les exemples.
Donc,
et le problème,
c'est qu'en fonction
des gens qui qualifient,
eh bien,
tout est possible.
Donc,
il faut faire en sorte
qu'il y ait un guide,
que finalement,
ils comprennent
ce que c'est que la qualification, etc.
Et pourquoi ?
Et donc,
quand il y a des subtilités,
pourquoi il faut ranger
dans telle propriété
et pas telle propriété, etc.
Donc là,
il y a eu un guide
54 pages
en six langues
pour expliquer
comment vous allez qualifier,
chers amis.
Voilà.
Donc,
voilà,
c'est rapport qualité-pris
et bon,
c'est prize-value,
positive.
J'avoue que le prix,
j'en suis super content.
C'est très positif.
Parce qu'en plus,
à l'époque,
on était un peu,
comment dirais-je ?
Non.
On y croyait.
Donc,
on avait
neutre,
positif,
très positif
et négatif,
très négatif.
Bon,
au bout d'un moment,
on est un peu abandonnés.
Bon, là,
c'était le démarrage.
On dit,
ah ouais,
génial,
on va pouvoir faire
des petites subtilités
sur le niveau.
Je vous encourage
à pas le faire.
Un compatique
compliqué, voilà.
Voilà.
Quand le prix n'est pas justifié,
c'est trop cher pour ce que c'est.
Voilà.
Donc, gros truc
et
développement
d'une application
pour qualifier
tous les postes qu'on reçoit,
etc.
Donc, c'était vraiment,
on était en mode un peu
hystérique.
Donc, voilà.
On a un problème.
Tiens, on va développer
une application.
Bon,
c'est ça.
Un problème,
une appli, non ?
C'est pas ça.
Bon.
Donc,
sachant quand même,
il y avait un client
qui était intéressé.
Donc,
on claquait pas l'argent uniquement
dans la pure
R&D.
Donc,
ça,
c'était
la version précédente,
la dernière version.
Donc, là,
justement,
c'était dans une vision
plus générique,
parce que là,
l'autre,
elle était
très
très ciblée
pneumatique.
Alors,
notre objectif,
c'était du pneumatique.
Donc, là,
on avait une version,
mais globalement,
ça revenait au même.
C'est de dire,
on repère les entités
nommées,
on met un certain nombre
de choses en avant,
etc.
Voilà,
pour pouvoir
qualifier automatiquement.
Mais,
il est vraiment,
de toute façon,
le cœur du système,
c'est,
enfin,
à cette époque-là,
il fallait créer
une vraie base de
qualification
full option.
Ensuite,
donc ça,
hop là,
des gens,
il y avait des années,
je ne sais pas,
dix ans,
d'avant,
plus plus.
Donc,
il y a des gens qui ont
qualifié,
dans toutes les langues,
dans six langues,
pof pof pof pof,
les blogs,
les machins,
bah bah bah.
Bon,
on revendait aussi
les résultats,
quand même.
Donc,
ne nous plaigniez pas,
ça allait bien.
Alors,
les prêts traitements,
quelques petites choses
générales.
Donc,
tout ce qu'on faisait,
bon,
évidemment,
les bruits de fonds,
les caractères spéciaux,
etc.
Le basique,
bon.
Ensuite,
il y a aussi le concept
de documents uniques,
parce que,
quand vous aspirer
des blogs dans un temps,
il y a des références,
des citations,
qui citent autre chose,
qui citent autre chose,
qui citent autre chose.
Et quand vous l'aspirez,
vous récupérez la totalité
du truc.
Sauf que ça biaise.
Parce que,
finalement,
avec un autre blog,
vous allez récupérer
l'élément élémentaire
qui a servi de citation.
Bon.
Donc là,
en gros,
et après,
on a fait aussi
les trucs bien classiques.
Il n'y a pas d'invention
par rapport à ça.
La lématisation.
Donc,
lématisation,
c'est simplement
transformé
en une forme canonique.
Donc,
c'est ça.
Donc,
au démarrage,
il faut toujours remonter,
à l'époque,
il n'y avait pas 36 bibliothèques
qu'ils faisaient.
Il y avait Trittiger.
Maintenant,
on utilise Spacey.
Donc, voilà.
Donc,
l'objectif,
c'est de traduire
les mots en une forme canonique.
Et puis,
qui permet d'associer
à chaque,
finalement,
l'Ème qu'on a récupérée,
finalement,
sa classe grammaticale.
Ce qui va être assez intéressant,
parce que pour l'optimisation
qu'on va faire derrière,
ça va nous permettre
d'éliminer des choses
qui ne nous servent à rien
pour
la tonalité
ou la qualification.
On se rend bien compte
que déterminants
nous en font.
Alors ensuite,
détection d'entités nommées.
Voilà.
Vous allez dire
ça,
ça sort d'une...
C'est bien un truc d'une publique.
Ben oui,
ça sort d'une publique.
Bon,
c'est pas grave.
Ensuite,
j'avais dit que je ne mettrais pas
de trucs de publique.
C'est raté.
Alors,
donc,
petite remarque,
en parallèle,
il y avait quelque chose
que l'on développait,
qui était
un résulté OVE.
Si vous cherchez des pneus,
vous avez un site Internet
qui s'appelle Résulté O.
Bon.
Qui existe
dans tous les pays européens
et qui permet
de chercher
le pneu le moins cher.
Voilà.
Bon.
Donc c'est un peu
notre vitrine
des gens.
Et donc là,
on avait une idée
aussi géniale
de dire,
classiquement résulté O,
c'est comme les sites...
Je ne sais pas
si vous avez déjà acheté
des pneus
sur des sites Internet.
Mais la plupart du temps,
c'est soit vous sélectionnez
la marque,
soit vous sélectionnez
la dimension de vos pneus
avec des bonnes
et des lises déroulantes
et vous sélectionnez
la dimension.
Hop.
Vous faites recherche
et puis vous trouvez.
Et nous,
on voulait faire un truc
nouveau.
Bon.
Je cherche un pneu
pour ma Clio 106,
enfin pour ma Clio 2006
et je préfère les Michelins.
Poum.
Et ça sort le résultat.
Voilà.
C'est plutôt sympa.
Donc on a à faire un truc.
Alors,
beaucoup de gens qui disent
que ça marchait.
Mais,
de temps en temps,
c'était surprenant les résultats.
Mais,
mais en tout cas,
non mais,
non parce qu'il y avait des trucs,
c'est...
Bon,
je ne reviendrai pas
sur ce truc.
C'est un truc de...
C'est de la recherche,
donc c'est particulier.
Bon.
Non, mais c'est de la recherche.
Ça veut dire,
de temps en temps,
il y a des véhicules.
Je me rappelle d'un exemple,
la golf-édition spéciale
Pirelli.
Pirelli,
c'est une marque de pneus.
Donc pour dire
que ce
édition spéciale Pirelli,
en fait,
non,
c'est un véhicule.
Et qu'il ne faut pas considérer
Pirelli comme
uniquement la marque
que l'internaute recherche.
Eh ben,
là, ça ne marchait pas.
Voilà.
Donc systématiquement,
il voyait que les Pirelli,
ils comprenaient pas pourquoi.
Bon.
Donc,
donc,
on avait ce système de recherche
automatique,
finalement,
sur une requête de recherche
pour extraire les entités nommées.
Pour revoir,
pour extraire ça.
Il y avait tout ce...
ce truc ce petit.
Donc, on s'est dit,
ben,
tiens,
ça serait intéressant de faire ça.
Donc,
c'était première axe,
via l'analyseur.
Ensuite,
deuxième axe,
on a fait un truc avec un laboratoire,
on aime bien travailler
avec les laboratoires.
Et eux,
ils ont fait un système
de post-tagueur.
Donc,
le post-tagging,
c'était de dire,
ben voilà,
je mets un texte
et finalement,
au lieu de taguer
avec une classe grammaticale,
je tag avec
une classe bien ciblée.
Ah ben voilà,
ça,
un maker,
ça c'est le name d'un produit,
ça c'est l'autre name
d'un produit,
etc.
Donc ça,
le tag.
Le problème,
c'est que
des post-tagueurs,
ben,
il faut leur apprendre.
Et donc,
bon,
voilà,
et puis,
là,
c'est que sur la vision
pneu,
après,
il y a le véhicule,
il y a machin.
Donc,
on a fait tout un tas d'essais
où on a généré,
finalement,
à partir de notre référentiel,
tous les textes de recherche,
etc.,
des classes
de chacun,
des...
des...
des tokens.
Bon.
Donc ça,
ça a été aussi
un élément intéressant
en 2015.
Ensuite,
on est revenu
plus pragmatiquement
sur une vision basée
sur des dictionnaires,
Elasticseur chez mon ami,
et des expressions régulières.
Et ensuite,
un autre truc
qui avait super bien marché,
génial,
c'était avec
des réseaux de neurones.
Donc là,
celui qui marchait le mieux,
c'était,
je me rappelle bien,
les STM.
Voilà.
Bon.
Donc plein de choses
qu'on avait pu
tester.
Alors,
quand vous regardez ça,
vous dîtes,
ah bah génial,
il n'y en a qu'un.
Et celui-là,
il doit être génial
parce que là,
il marche à chaque fois
même qu'on bat.
Ça marche génialement,
mais il faut produire
une base d'apprentissage
par rapport à tout ça.
Donc,
il fallait comprendre
des textes,
qu'on insère
les noms,
les entités dans les textes,
de telle manière,
une base d'apprentissage
pour pouvoir apprendre,
finalement.
Alors,
comme c'est très moine,
c'est GPT à roulettes,
là,
c'est vrai,
le mot suivant,
quoi.
Sauf que le mot suivant,
il peut être énergie,
il peut être machin,
il peut être plein, plein, plein, plein de choses.
Donc,
bon,
compliqué.
Donc,
moralité,
à la fin,
qu'est-ce qu'on a fait ?
L'éthiqueur MofoSynthesity,
on a abandonné,
parce que
il fallait générer
une telle masse.
On n'est pas à Google,
on n'est pas
OpenAI,
on n'est pas machin,
on n'est pas Microsoft,
donc on n'a pas
des capacités de calcul infinie
pour générer tout ce qu'on veut.
Donc ça,
pouf !
Bon,
là aussi,
même combat,
si il faut qu'on génère
tous les trucs,
c'est mort.
Termes basés sur des dictionnaires,
ben,
finalement,
ça marche pas mal.
Donc,
on a un beau référentiel,
on a plein de bases
de,
comment dirais-je,
de règles,
de synonymy,
etc.,
qu'on a derrière,
donc finalement,
ça marchait super.
Alors,
on a essayé aussi
des bibliothèques
qui détectent automatiquement
les entités nommées
quel que soit le domaine.
Voilà.
Bon.
C'est énormément de bruit de fond,
donc on n'avait pas
des bons résultats.
Donc finalement,
vous voyez,
c'est le truc le plus nier
qu'on a sélectionné
pour la prod.
Je veux pas dire
que les trucs non-niers
sont pas bons,
mais c'est toujours
nécessaire
à fabriquer
la base d'apprentissage.
Alors,
détection.
Donc là,
c'est bon,
on a résolu le problème
des entités nommées.
Alors,
au fur et à mesure,
parce qu'on a
fait plein de versions,
comme vous avez pu le voir.
En parallèle,
on travaillait,
cette fois-ci,
sur l'extraction des qualifeurs.
Donc,
la partie
je roule
sous la pluie
ou je machins,
enfin,
freinage,
voilà,
tous les éléments.
Là aussi,
il faut revenir,
2014,
réseau baïsien,
machin, etc.
Pas le génial.
Donc,
on a fait appel
à une linguiste.
Vous avez dit,
bah,
une linguiste,
je connais bien
le langage,
je connais bien les trucs.
Donc,
donc effectivement,
elle a créé
tout un système
avec des règles.
Alors,
c'est...
Donc avec
tout un système
avec la notion de contexte,
donc il y avait
toute une collection de contexte.
Voilà,
par exemple,
la notion de contexte,
c'est,
on a soit tailleur,
soit tailleur, soit rubber,
ça c'est pour l'anglais.
Avec
soit une entité nommée,
soit un peu,
un prénom
de co-référence,
et on a un adjectif
ou un nom derrière.
Voilà,
un contexte.
Donc,
on cherchait
tous ces contextes.
Alors,
il y en avait une collection,
une douzaine de contextes.
Et à partir de ces contextes,
on récupérait des informations
statistiques
sur ces contextes.
Voilà.
Donc,
des F-scores,
des machins,
enfin,
les trucs classiques.
Bon,
génial,
on a une énorme base
avec plein de trucs,
avec la fréquence
des mots,
par contexte,
machin, etc.
Après,
ce qu'elle a fait,
la phase
d'inférence,
on a tout ça.
Maintenant,
on donne un texte.
On dit
l'entité,
là.
Maintenant,
alors,
ça parle de quoi ?
C'est quoi les calculs ?
Et là,
on avait un algorithme.
Alors,
j'ai pas mis toutes les pages.
Je dirais
d'experts linguistes.
Et il y avait une déclinaison
pour chacun des algorithmes
en fonction des langues.
Parce que chaque contexte
était différent
en fonction des langues,
etc.
Voilà.
Bah,
finalement,
on a obtenu des résultats.
2017.
Donc,
enfin,
2017,
la première mise en production
géniale.
Enfin,
géniale.
Ça marchait,
la mise en production
n'a pas été si simple
que ça,
etc.
Enfin,
parce que
c'est une linguiste.
Comment dirais-je ?
Euh...
C'est pas une informaticienne.
Démarrage.
Donc,
tout le
manifestement,
c'était en perle.
Perle,
c'est pas le langage
ne plus maintenant
qui existe au monde.
Donc,
bon,
par contre,
c'est un super anglais
pour manipuler du texte,
etc.
Donc,
voilà,
des résultats.
Pas de problème.
Et après,
on s'est dit,
oh putain.
Parce que,
à chaque fois,
on avait à remonter des gens,
parce que
cette première version
c'était censée,
enfin,
dans le système de qualification,
le système
des gens qualifiés
à la main.
Grâce à Stadorite,
on pré-sélectionnait
les qualifiaires.
Donc,
ils avaient pas besoin
de dire à eux,
le texte,
il parle de
prénage sur seuls mouillés,
on y parle de ça.
On pré-établissait
tous les éléments
qui étaient à l'intérieur
de la description.
Donc,
finalement,
c'était une aide
à la saisie
des gens
qui qualifiaient.
Donc,
ils n'avaient plus qu'à valider,
ou à déqualifier,
ou à enlever des choses, etc.
Donc,
c'était vraiment
une aide pour eux.
Sauf qu'évidemment,
il n'a pas repéré ça.
Ah ça, mais c'est n'importe quoi.
Il donne cette qualification-là,
il ne faut pas le faire,
c'est-à-dire.
Bon.
Et donc, on s'est dit,
on va rester d'améliorer.
Quand vous avez des tonnes
et des tonnes de pages de perles,
c'est compliqué.
Donc, on s'est dit
aux petits tuyaux.
Si on pensait à autre chose,
soyons plus
bestiales,
c'est bien ce mot.
Donc là,
maintenant,
l'apprentissage d'automatique
et pothéraste
et tout ça,
en même temps.
Donc,
l'apprentissage d'automatique.
Alors là,
on a lancé deux axes.
Je parlerai que d'un,
celui qui a été mis en preuve,
il y a un axe par un pésar.
C'est la proche du multilabel,
c'est-à-dire
qu'on essaie de trouver globalement
tous les labels
qui sont associés
à l'entité nommée, dans le texte.
Là, on a dit,
non,
c'est la belle par la belle.
Les uns après les autres,
donc,
c'est un peu délicieux.
Donc,
on apprenait un modèle
par langue et par téléphère.
Donc,
les autres données,
c'est les mêmes que d'habitude.
Alors,
petit remarque,
évidemment,
c'est comme tout
système d'un MP,
vous avez beaucoup de trucs
positifs,
pas,
il y a énormément de trucs neutres,
des trucs positifs
et peu de trucs qui gagnent.
Donc,
c'est un délicieux,
un délicieux d'apprentissage,
qui est particulièrement déséquilibre.
Donc ça,
ça l'est un vrai problème
pour nous aussi,
pour nous d'apprentissage.
Donc,
on a fait,
au départ,
voilà,
on a fait du TFDF,
on a testé différents
algorithmes d'apprentissage
standard.
On n'est pas
lancé dans le,
comment dire,
dans la classification.
Peut-être là,
c'est de la classification,
ou un classique.
On a fait des algorithmes,
avec l'action logistique,
Pond of Forest
et
MyBind,
mais les algorithmes bien.
Ouais.
Donc, on s'est dit,
bah voilà.
Hopstier.
Super résultat.
En fait, non.
On avait un peu oublié
un petit quelque chose.
C'est très léger.
C'est très léger.
Là,
on a pris tous les éléments,
on s'est vu,
TFDF, etc.
Et on a fait
le test
avec
un sous-ensemble
qu'on avait extrait,
etc.
Sauf que le sous-ensemble,
lui,
l'avait aussi participé
au TFDF.
Bah oui.
Sauf qu'en fait,
dans la réalité,
quand il y a un nouveau poste
qui arrive,
c'est un poste qu'on n'a jamais vu.
Donc,
à l'intérieur,
il faut y avoir
des mots qu'on n'a jamais vu.
Donc,
donc là,
on s'est dit,
mais il y avait un lieu
auquel lui ajoutait
cette vérité.
Donc,
ça paraignait
comme
erreur.
Je sais bien combien.
Mais bon,
on était dans une espèce
de fondieux.
En réalité,
on a corrigé ça
et là,
les résultats ont été moins bons.
Mais,
on t'a réveillé là-dessus.
Donc, poste négatif,
poste positif,
on a un téléphone,
on a des réalisations en commun.
Le poste négatif,
que pour
le trend test,
et puis ensuite,
on a retrouvé les éléments
par rapport
à la poste tirée.
Bien.
Alors,
ce type d'amélioration,
on a fait plein de choses,
parce que là,
il y a eu du temps,
tout ça,
19, 2021.
Donc,
aux résultats,
augmenter la taille
du vocabulaire
peut-être,
meilleure les choses.
On monta le ratio
de poste positif.
Donc là,
on a fait tout un système
où en fonction
du nombre
de postes positifs,
du ratio de la longue,
etc.,
qu'elles aient fait
les meilleures ratios
d'augmentation
du nombre d'éléments,
enfin,
le négatif,
le polygne.
Là,
on avait fait du TFIDL,
on a testé
une retrouvée classique,
en fait,
comme haute représentation
ensuite, on avait,
et là aussi,
il faut dire,
poste,
quand on parle de poste,
alors,
les gens, tu te dis,
ben oui, c'est un petit texte,
ils parlent d'un truc,
voilà.
Dans un temps,
il y a des gens
qui mettent des pages,
qui parlent de tout
et n'importe quoi.
Enfin,
au début,
ça parle de pneus,
après ça parle de
plus dernier,
de mon garage,
rallye de formule 1,
un vrai certain,
avec des choses.
Bon,
donc,
là,
il y a différents éléments,
il peut y avoir
différentes entités nommées
qui sont à l'intérieur.
Donc,
l'objectif,
c'est de découper le poste
de telle manière,
à dire,
oui,
je le prends,
l'entité nommée,
je le prends,
tous les textes,
qui sont autour
de cette entité,
soit directement,
soit par
coucure.
Donc,
voilà.
Donc là,
on a les pages complets
et les pages découpées.
Comme ça,
au moins,
parce que,
on faisait que les pages
découpées avant,
bon,
le roi de la
de la classification,
où j'ai tous,
bon,
là,
on va intégrer.
La notion de sali de califière,
on reviendra là-dessus,
par rapport à tous les tests
qu'on a fait,
parce que là,
c'est qu'on a fait que tester,
tester, pour voir les résultats,
etc.,
pour dire,
c'est quoi les ratios,
les plus optimales,
par rapport au nombre
de poste en 1,
etc.
Et,
donc,
une notion de sali,
et puis ensuite,
à la fin,
on a fait un baili,
donc le but,
c'est de regrouper,
un bot,
enfin,
un peu d'aliment.
Et ensuite aussi,
pour des raisons de performance
et aussi,
d'être populiste et volontaire,
enfin, plus direct,
l'implication du moteur du verre.
Donc,
les classes dramaticales,
en fait,
elles sont importantes,
parce que,
à la fin,
on me conservait que les classes
pertinentes, en fait.
Les éléments,
le la,
le machin,
les trucs,
la verbe,
le verbe,
le touche,
ça,
on a tout dit à eux.
Bon.
Et,
puis,
de petits trucs,
on va pas dire,
ils sont très gaises,
donc voilà.
Bon.
Non, je m'y agris.
Vous êtes trucs très très ciblés,
c'est pas mal.
Donc voilà,
quand je disais
qu'à la fin,
on a essayé de
découper ça,
c'est nos familles,
en fait,
voilà,
les typologies,
de dire,
bah bah,
non, ce truc,
pour cette langue-là,
etc.,
bah,
est-ce qu'il y a des familles
de qualité?
Oui, non.
Il peut être normal
et ça,
c'est l'objectif.
MAN stitches,
batteries comp Skills,
國 Jugais, etc.
On définissait,
finalement,
un certain nombre d'éléments
qui nous permettent
de piloter le choix
qu'on va en faire,
dosés hyperparamètes
qu'on va,
ography,
sur radar.
Et alors,
on a retenu
peut-être
tous les modèles,
ok,
mes wegen我很
sou dólares pour le commun,
et régression logistique.
En tout cas,
sur les artificies,
combien.
Donc voilà,
on peut les résultats.
C'est toujours sympa
de voir les résultats.
Bon évidemment,
vous allez dire,
bros,
c'est un peu déprimant.
Bon,
il y a quand même des résultats
qui sont pas mal.
Pour
le cas du Sphere
493,
c'est vrai
que j'aurais dû mettre
le gant,
ça correspond.
Oh,
c'est super bon.
Bon,
j'appelle ça
super bon.
Mais,
sur le 619
on n'est pas bon du tout.
Bon après,
c'est une vision,
typologie,
ça c'est du normal.
Donc dans les normaux,
on est plutôt vrai.
Quand on a des ratios faibles,
etc.,
donc c'est par rapport
à la typologie précédente,
exactement,
on n'a pas assez de
le texte,
on n'a pas assez d'exemple,
etc.
Le ratio,
finalement,
de base,
même si on bouche le truc,
d'excès extrême,
alors,
il y a des extrêmes,
on y arrive bien,
finalement,
transformé.
Bon,
et vous voyez,
on a très peu de postes
sur le Nérandais.
C'est une langue particulière.
Bon,
mais toujours est-il que,
ça allait bien.
Enfin,
du cas,
on a fait,
alors ça c'est le
pipeline total,
final,
full option.
Non mais,
on va dire,
c'est pas ce délinir.
Non mais,
il y a des trucs,
c'est tout bête,
on détecte la langue,
parce que,
on entend,
il y a des trucs,
mais c'est pas toujours la bonne langue.
Bon,
on charge les modèles spécifiques.
Bon voilà,
voilà,
on,
on fait,
comment dirais-je,
nettoyage,
délinible,
post-tagging,
on les baptise,
on applique les synonymes,
voilà,
et là,
on applique l'abstiture,
maintenant,
splitting, etc.
On coupe les éléments,
et puis là,
il y a vraiment la partie
classification,
c'est en bas.
Là,
c'est la partie pré-processing,
et la partie classification,
c'est vraiment celle-là.
Donc,
ça fait quelque chose,
donc là,
c'est pour récupérer
les modèles,
tout le monde.
Faire cette situation,
c'est pas une plainte,
non,
c'est une plainte,
une logique.
Et ça,
c'est la partie
apprentissale.
Donc là,
on nous tient des modèles
à la fin,
il faut faire une assurance,
c'est la fin.
Donc,
on a aussi un petit truc
d'inférence,
quand même.
Voilà.
Mais là,
plus simple,
on load les modèles,
on a le pré-processing,
et après,
la classification,
on a un nouveau post-post,
quel antiterre,
quel machin,
quel canifereur.
Hop, ça sort.
Donc après,
dans la réalité,
la vraie vie.
Donc là,
il y a les résultats
de l'apprentissage.
Dans la vraie vie,
bah voilà,
les sorts qu'on a.
Alors,
c'est vrai que
on a une amélioration,
par rapport à l'ancienne version.
Elle est appelée le catalysme.
Bon, là,
c'est plus classique.
Alors ça, c'est plus classique.
Le plus raisonnable,
Ronald.
Alors,
je ne sais plus
ce que ça veut dire.
Bon.
Alors,
il n'y a pas
une grosse amélioration
du catalysme,
avec toutes ces règles
d'extraction, etc.
Enfin,
finalement,
avec nouvelle,
quand elle qualifiait,
il y avait beaucoup de plateaus,
c'est-à-dire,
il y avait beaucoup de postes,
bah non,
on ne trouve rien.
On ne trouve rien.
On ne trouve rien.
Là,
dans la plupart du temps,
on trouve toujours quelque chose.
Il faut aussi voir ça,
le pourcentage par rapport
à la couverture.
Donc,
on a augmenté le pourcentage,
et maintenant,
on a augmenté la couverture par rapport.
Donc,
donc, il y a avant,
c'est-à-dire,
c'est-à-dire,
après,
on peut s'amuser
avec les éléments passés.
Là aussi,
tout dépend
de ce qu'on veut faire.
Est-ce que,
là,
c'était dans la vision
d'essayer d'aider
les gens qui qualifiaient.
Prémâcher,
finalement,
c'est de la qualification manuelle.
Si on était
dans une vision
où je veux faire du fou,
le thématisme,
c'est différent.
Là,
on pourrait te faire bien vivre.
Ah oui, mais
on va être beaucoup plus arnes.
C'est-à-dire,
on va augmenter
la masse
de données qu'on va récupérer,
ouvrir les vagues,
comme on nous dit,
on nous touche,
on touche qu'on a.
On ne basse pas uniquement
les éléments et les sous-ensemble
qu'on passe aux gens
pour la qualification.
Et là,
par rapport à tous nos diverses paramètres,
on est beaucoup plus arnes.
Donc,
pour l'idée,
on va monter grandement
tout ce qui est
le résultat.
Mais,
peut-être qu'on va dégringoler
à ce niveau-là.
Mais,
tout dépend,
parce qu'on veut dire
qu'ici,
l'action de base est de dire
je considère que
finalement,
on ne va pas avoir de billets
par rapport à ça.
C'est-à-dire que
les résultats qu'on va avoir
en ouvrant les mains
de l'automatique,
mais
en étant
certains du résultat,
statistiquement,
quand on revient,
on a l'action,
on a l'aide,
en fait,
c'est
ce que l'on dirait,
le paranime,
ce que l'on croit,
ça va quand même donner
des résultats perçants.
Voilà.
Donc ça,
c'est
les petits éléments.
Donc là,
c'était avant et après.
Donc,
bah,
c'est un peu,
finalement,
il y a eu beaucoup moins
de création,
finalement.
Là,
c'était
une défendrement
des caliceurs
qui manquent.
Donc on en trouve beaucoup plus.
Bon,
effectivement,
il y a une montée des caliceurs,
ce qu'on parle,
ils ne sont pas bons,
parce qu'on a ouvert les mains.
Donc si on avait été
plus réducteurs,
bah,
c'est vrai.
Mais l'objectif,
c'était de dire,
il n'est pas bon,
c'est facile de chiffrir.
Enfin,
hop,
je supprime,
je supprime,
je supprime.
Créer un truc,
c'est que je vais me chercher,
je m'achange,
je vais associer,
etc.
Donc pour les gens
qui étaient
pour la qualification,
bah,
ils feraient ça.
Alors,
et là,
on a créé des caliceurs.
Dernier étape,
je ne sais pas,
au point de délire,
non,
ça ne va pas.
On délirait en termes de temps.
Détection de la ténagité.
Donc,
ça,
qu'est-ce qu'on a fait ?
Bah,
on a mixé de choses.
On a mixé,
parce qu'il y a plein de bibliothèques
qui existent
pour faire des détections
de ténagité.
Donc,
la bibliothèque
qu'on a choisie,
bah là,
c'est par rapport à différents tests
de bibliothèques,
c'est texte bloc.
Bon.
Bon,
ce n'est pas terrible,
quand même.
Mais bon,
ça sort quand même un résultat.
L'intérêt,
c'est
comment dirais-je,
pour le cas où on a,
comment dirais-je,
aucune information,
c'est pertinent.
Puis tout d'un coup,
on est sur un nouveau domaine
qu'on ne connaît pas,
qu'on n'a pas de base d'apprentissage,
bah,
c'est mieux que rien.
Autrement,
on a pris
un autre modèle d'apprentissage,
cette fois-ci,
donc on n'a rien critiqué
exactement le même principe
que précédent,
mais cette fois-ci,
à la tonalité.
Donc,
on a appris la tonalité
par rapport à tout ce qui avait été
fini dans la base d'apprentissage.
Donc là,
gros élément
et
bon,
beaucoup de résultats
à la hauteur,
comme la visite,
bah,
on est bon,
on est positifs,
on va dire,
aléatoires en nôtre
et en égalité.
Non, non.
Alors,
de toute façon,
c'est la mille,
être un store, etc.
C'est le nombre d'éléments, vraiment,
qu'on a raccrochés,
etc.
Bon.
Donc là, finalement,
le choix du modèle hybride
a été plutôt
meilleur que l'utilisation
de la bibliothèque.
Donc,
c'est ce qu'on a sélectionné.
Et maintenant,
tout l'unard,
tout m'avait dit l'unard, pas mal.
Alors,
il faut poser une question après.
Hop là.
Alors,
dit pitcher.
Parce que là,
ce qu'on a fait,
notre objectif,
c'est de faire d'autres choses.
Parce que là,
on a fait des trucs
par rapport à
les coups.
Voilà.
Sauf que
tout ce qu'on a,
tous les modèles,
tous les trucs,
ça ne marche que pour les coups.
Mais,
voilà.
Notre objectif,
c'est justement,
c'est de faire,
d'appliquer la même chose
sur d'autres domaines.
Bon, l'hybrision,
parce que non,
je ne pense pas que c'est
pénage-chanson mouillée
qui les intéresse beaucoup.
Je ne sais pas,
mais c'est super.
Or,
là,
on n'a pas le temps
de mettre X-bonon
pour qu'elle ici.
Alors,
il n'y a pas le temps
de mettre X-bonon
de faire un coup,
ou ça,
de calificier, etc.,
plein de temps,
il y a dit ça.
Donc,
l'objectif ici,
c'est de dire
se passer
de la calification manuelle.
En tout cas,
de minimiser au maximum
la calification manuelle.
Comment c'est
l'idée qui est derrière
et qui a
fait l'objet de la thèse
qui va être
soutenue en mars,
c'est de dire
qu'à partir de
tous les textes qu'on a
sur le jeu,
j'ouvre les valles,
je prévue tous les blogs.
Donc là,
c'est pour
le revêtement de sol.
On a fait des trucs
pour le revêtement de sol.
Voilà.
On a plein, plein, plein
d'éléments qui arrivent.
On mouline
la durée.
Et ça nous sort
via...
Alors, la durée,
c'est dans la philosophie
topique manuelle,
topique modeste.
Donc,
ça définit
et sans apprentissage,
ça sort
des thèmes principaux.
Automatiquement.
Donc, c'est
autant que ce que
vous avez vu précédemment,
c'est du supervisé,
base d'apprentissage.
Là,
c'est
totalement non-supervisé.
Alors,
ça va être génial,
des thèmes comme ça.
Bon, c'est
plus simple que ça
parce que
ce que l'on appelle
un thème,
c'est
une connexion de mots,
en fait,
qui sont rangées
par fréquences, etc.
Enfin, bon.
Donc, toujours est-il
qu'il y a des mots
avec des mots, etc.
et ça représente
les thèmes.
Bon, évidemment,
alors,
il devrait utiliser
gp3
ou gp2.
Avec cette lignement
que ça bruit,
un nom de thème sympa.
Bon.
C'est pas vrai.
Ça,
ça pourrait être intéressant.
Bon, la plupart du temps,
c'est les mots principaux
qui sont élus.
Donc,
ça représente ces thèmes
et finalement,
c'est nos thèmes.
Enfin,
c'est tous les qui sont
élus automatiquement.
Ça va être, finalement,
les thèmes.
On ne connaissait rien
dans ce domaine.
Bah voilà,
les thèmes principaux
qui ont les noms.
À partir de là,
on a des thèmes.
Alors,
on peut appliquer
de la classification
par ces thèmes
qui sont associés bien
à des éléments
dans les blogs
par rapport
à des mots importants,
etc.
Donc,
on peut
reconnecter
sur le technique
d'apprentissage
et de dire,
je base sur ces thèmes
qui ont été détectés
pour apprendre
les thèmes
au sein
du modèle.
Enfin,
au sein de tous les blogs
qui ont été créés,
finalement, un modèle,
sans que personne
n'ait qualifié
quoi que ce soit.
Donc,
c'est ça,
l'idée
qui est derrière
la beat picture.
Donc,
évidemment,
il y a toujours
l'extraction
qui était nommée.
Donc là,
voilà,
le revêtement de sol.
Donc,
on doit
toujours trouver
les entités nommées.
On a le truc
avec ces topiques qualifiaires.
Par contre,
pour la tonalité,
là,
il n'y a pas de miracle.
On va pas faire de l'apprentissage.
Donc là,
on va devoir
utiliser
une bibliothèque
ou
un petit x-ray
pour
détecter,
finalement,
la tonalité
qui va être associée
à ce morceau de texte
qu'on va suivre.
Et donc,
ensuite,
c'est terminé.
Là,
on a créé un modèle
que personne n'ait jamais intervenu
par rapport
à une idéalité de trois trucs.
Il faut intervenir sur
peut-être les topiques,
leurs travaillées,
etc.
Donc,
ça sera un truc coréen.
Mais en tout cas,
on n'aura pas fait bosser
x-personne
pendant 10 ans
avec un ici,
chacun des deux oeufs.
Elle veut dire
c'est ça.
C'est la prochaine
qui est nommée.
Et l'objectif,
après,
on a un nouvel élément
et ça nous sort.
Le résultat
c'est
tel or si t'es nommée,
tel thème
ou tel collection de thème,
quel tonnage pour chaque année.
Voilà.
Donc ça,
il va y avoir un premier test
qui va avoir lieu
en 2023.
Alors ça va être
sur des
diversifiés.
Donc ça va être
sur les produits blancs
et produits bruns.
Merci.
Donc les machines à l'aéros,
les machins,
les...
les utilisateurs.
Donc
pour sortir les thèmes
les plus
utilisés,
enfin,
les plus discutés,
évidemment,
et ensuite,
canifier d'une manière automatique
les éléments qui sont
sortis.
Voilà.
Pile une heure.
Merci.
C'est parfait.
T'as mis la pression.
Oui, tu as mis d'une heure.
Apptiez.
Je sais pas si vous avez...
Ah, je pense que tout le monde
a envie de boire un cours
et manger des pizzas,
mais si vous avez
déjà des questions
ou des choses,
vous vous avez assommé
une manière active.
Ah,
c'est fatigué.
Je ne sais pas.
Je ne sais pas.
Bon, je ne sais plus
que vous avez mis
des questions.
Alors, c'est un algorithm
qu'on a développé.
Ah, OK.
Donc,
qui est présenté,
d'ailleurs,
il y a une conférence,
c'est la sphédianique
qui est présentée,
je crois,
le GC, là.
Et donc,
c'est un algorithm
particulier,
donc on s'est basé
sur les travaux,
on va dire,
mais ça s'appelle déjà
un...
un gain.
Voilà.
Voilà.
Il y a deux Grands Masters, en fait.
Et il y a une déclinaison
qui a utilisé, effectivement,
le bandirage
de la...
enfin,
une transformation de l'algorithme
de telle manière
à être plus pertinente
et aussi
à permettre
l'évolution dans le temps.
Il y a deux algorithmes,
en effet.
Une vision
que bandirage
en utilisant
la propagation lexicale
à l'intérieur
de l'algorithme
de la topikmonie, on va dire,
et ensuite,
la vision dynamique,
parce que le gros problème
du topikmonie
c'est que
on en a déjà fait
pour d'autres
étudiants,
l'extraction automatique
de telle,
sauf que
comme on dirait,
nous voulons suivre
les telles
pour dire, justement,
les telles, l'alarme,
les chingues, etc.
sauf que, au fur et à mesure,
une telle,
vous pouvez évoluer.
Et,
en réalité,
quand on fait le classement
dans la classification,
bah là,
ça commence à
poser des problèmes,
parce que, finalement,
il y a des nouveaux thèmes
qu'il y a pas,
et donc,
la vision
qu'on avait
dans le temps
se déforme.
Donc,
ça va s'il vous plaît,
vous avez pas de problème
dans la justification ?
Bah,
pour l'instant,
on va,
on est dans un mode,
on part,
comme on est
dans un mode
comme on dirait,
une nouvelle donnée,
on va pas avoir
beaucoup de données
dans le temps.
Donc, là,
on est
on espère que,
bah, je sais pas,
typiquement,
sur le domaine des produits blancs et bruns,
j'espère qu'il y a pas
des thèmes qui apparaissent,
générations spontanées.
Bon,
je sais pas,
je suis pas très au fait
de ces produits-là.
Par contre,
les éléments,
les tests
entre tes arts,
lui, c'était sur,
bon,
des jeux de données classiques,
on va dire,
qui, par rapport
à tous les contenus,
de l'ONU,
etc.
Donc là,
évidemment,
les thèmes sur plusieurs années,
ah, c'était sur,
pas un temps, un temps,
un temps,
là, on voyait bien
l'évolution des problèmes
qui a bien changé,
la crise climatique,
c'est pas,
bah, c'est,
voilà,
le câble,
on n'a pas reçu
relativement ça,
non,
donc,
c'est pas parce que
vous vous regardez
oui,
comment vous mettez
en production, en fait,
franchement,
par de la recherche,
à vraiment
mettre ça chez le client,
c'est tout.
Alors,
très bonne question.
Je reviendrai,
petite expérience,
je remonte dans le temps,
pas forcément sur les DLP,
à une époque,
on était vraiment
un truc de R&D,
pure R&D.
Voilà,
comme ça,
donc, on développait
nos algorithmes en d'autres coins,
en R, en machin,
pas de trucs,
et on disait,
bah, voilà, l'algo, c'est ça,
alors, c'est ça,
on expliquait,
c'est une forme d'une feuille,
voilà,
parce que je me suis accepté en feuille,
et je me rappelle,
ça m'a beaucoup marqué,
ce qui fait qu'on a changé,
en l'éclu, maintenant,
ça m'a beaucoup marqué,
où il y avait un petit algorithme
qui permettait de détecter
automatiquement
le cycle de vie d'un produit,
c'est-à-dire de dire,
est-ce que le produit que j'ai,
est-ce qu'il est en phase
d'apparition sur le marché,
de stabilisation,
d'éclins,
ou de mort.
Bon, ça, c'était important pour nous,
parce que, hélas,
les produits morts sur le marché,
il y en a énormément qui se marment.
Ils sont toujours en compte,
bon, voilà,
je ne sais pas pour toi,
mais...
Les produits sur le marché,
sur le net,
c'est comme ça.
Bon,
et donc ça,
dans l'algorithme,
il y avait deux pages.
Je me souviens...
L'implémentation,
dans la prod,
on va être gentil,
du rien.
Alors,
je mets un petit bémol,
quand même, c'est méchant,
parce qu'en même temps,
on était, on migrait,
enfin, on changeait de paradis,
aussi, on passait en mode
build after,
architecture adou,
pour découvrir plein d'autres choses.
Donc la prod,
découvrir aussi,
nouvel infrastructure, etc.
Mais là, on s'est dit,
il y a comme un petit problème.
Donc,
maintenant, on a changé
complètement de clics.
C'est-à-dire que,
là, maintenant,
on est très proche de la prod.
Enfin,
de l'environnement,
on développe vraiment,
presque,
dans un environnement
du prod,
avec les mêmes technologies.
Donc,
typiquement, là,
on est...
chez nous,
on a encore changé,
non, on est sûrs,
mais bon,
ça reste la même chose.
On était avec Spark,
pour la partie vraiment massive,
voilà,
et on s'est spécialisé,
on ne fait que du piton,
pour la partie,
vraiment machine learning,
etc.
Comme ça,
le Spark,
il peut être mis,
vraiment,
et déployé directement
sur notre prod,
et le piton,
en fait,
ils encapsulent ça,
le coeur, etc.
Il n'y a pas de soucis.
Donc, là,
maintenant,
on est vraiment,
on va dire,
quasi,
enfin,
on va dire,
ils ont plus grand chose à faire,
à part des petits problèmes
de déploiement,
de machin,
de mise
dans l'infrastructure
de prod général,
mais en tout cas,
on est conforme.
Et ça,
c'est un truc fondamental.
Et là,
il m'en repérerait toujours,
c'est de pas.
Il faut me tuer.
Donc,
ça ne se passe pas possible.
Voilà.
Donc, voilà.
Donc, être le plus proche possible
de la prod,
je pense que c'est fondamental
pour
un truc de rédé,
quand même,
on me demande,
quand même,
de temps en temps,
de résultats.
Merci.
Je cherchais un peu de monde
pour formuler
la question
de manière
à peu près de vous,
mais
quel est
l'approche
de votre système, je dirais,
et désolé
si vous avez
déjà abordé cette question-là,
vis-à-vis
des fautes d'orthographe,
par exemple.
Ah ben,
ça, c'est...
Non, ben oui.
En fait, quelque part,
les fautes d'orthographe,
bon, après,
il y a beaucoup de choses,
justement,
l'intérêt
du World2V, etc.,
c'est qu'en fait,
ça fabrique pas mal de modèles,
en fait, par rapport à ça.
Alors, il y a deux choses.
Il y a les bonnes distances
de base
qu'on emploie
pour réduire ça.
Et le STEC,
comment dirais-je,
il est...
comment dirais-je,
la prolongation lexicale
positionne quand même
les mots
qui sont
avec un orthographe
proche,
évidemment,
utilisé un certain nombre de fois,
parce qu'il y a d'ailleurs
une utilisation,
mais ils sont proches.
Il y a également le truc de synonyme.
Donc, il y a pas assez,
il y a un petit truc de synonyme.
C'est tout au fond, là.
Voilà.
Ça,
c'est basé sur
des prolongations lexicales.
Donc, on le fait à la fois,
à ce niveau-là,
et on fait aussi
à la fin.
Oui.
Oui.
Je me permets
de rajouter,
juste,
dans un second temps,
il y a un autre cas,
peut-être aussi,
c'est
parfois les doubles,
les doubles
comme je
double le langage.
Ah oui,
bah ça,
c'est pas ça.
Est-ce que c'est
peut-être pas spécifiquement
dans le domaine
du pneu,
parce que ça,
c'est un peu moins,
mais oui.
Le double langage,
l'ironie,
les machins,
et tout comme ça,
là,
je peux le...
C'est plus frère.
Vous,
l'égarage,
comme...
Non.
A nous,
à notre niveau,
le domaine va s'adapter
face à ça.
Ça,
j'espère que,
enfin,
nous,
on considère que,
statistiquement,
il y a peu
de gens
qui utilisent
le double langage.
Là aussi,
notre but,
c'est de faire des indicateurs.
Donc,
c'est d'être une vision macro.
Donc,
s'il y a
x%
d'éros,
évidemment,
si tout le monde
utilise le double langage,
on fait des jeux de mots,
des trucs un peu vachins,
alors,
on est mort.
Mais là,
il y a beaucoup d'un produit,
par rapport à un autre,
vis-à-vis de telles propriétés.
Donc,
quelque part,
c'est pas le fait de dire,
oui,
j'ai bien trouvé,
sur ce blog-là,
ou cet élément,
ce petit texte,
ah oui,
j'ai bien trouvé que c'est positif
ou négatif,
etc.
Bon,
je me suis planté,
j'espère que,
dans la majorité des cas,
je me prendrai pas.
Donc,
c'est,
pour bien se dire,
c'est l'agrégation.
Et d'ailleurs,
d'ailleurs,
d'ailleurs,
on avait fait une étude
le fait de remonter d'un cran,
en fait,
de le dire,
parce que là,
souvent,
quand on a vu le résultat,
c'est un peu déprimant,
voilà.
Si on remonte au niveau,
simplement,
de la marque,
je ne parle pas du produit
élémentaire,
mais de la marque,
ou renautement propriétés.
Pour ça,
il y a des familles de propriétés.
En fait,
ça,
on est beaucoup plus juste.
C'est-à-dire,
si on agrège tout,
en fait,
quelque part,
l'erreur,
se
dista,
enfin,
c'est...
Ouais, c'est non.
Nous,
toujours,
notre philosophie,
de dire,
finalement,
augmentons le nombre de flux
de données qu'on qualifie
et espérons.
Enfin,
c'est un peu,
c'est un peu star.
Cette vision,
notre vision,
de dire,
voilà, c'est comme ça qu'on va
quitter le...
bah,
il faut beaucoup de données.
Ok.
Voilà.
Merci.
Désolée.
Mais,
le double langage,
l'ironie,
les trucs,
si on veut ça,
c'est...
Je ne crois pas.
La partie,
du coup,
abbreviation,
c'est partie des signalis?
Oui.
Et puis,
on a aussi,
il faut bien se rendre compte
qu'on a,
dans ce cas particulier,
alors c'est vrai,
sur les nouveaux systèmes,
ça sera compliqué.
Mais,
même pour les noms de produits,
en fait.
Nous,
on a
tout un tas de règles,
de matching, etc.
qui ont été stockées.
Donc,
ils nous permettent de passer,
non,
finalement,
dans la partie qui
détecte les,
enfin,
matchs,
les produits,
qui sont poules
sur les pages
achetées,
même,
pour dire,
ça correspond à telle ligne
dans le référentiel.
Là,
en fait,
on utilise
ce système-là,
on parle
le truc,
on parle les éléments,
et en fait,
il nous trouve
celui qui est le plus proche.
C'est l'avantage
d'avoir un historique
par rapport à ça.
On se traque mon frontier,
sans doute,
au problème,
si on est dans le,
enfin,
on va le voir,
parce que je ne connais rien
dans les produits blancs,
à part avoir acheté de temps
en machine à laver,
un peu comme ça.
C'est vrai,
il y a des noms,
les noms produits,
à part arriver,
vous le verrez vachement,
un truc mieux,
je ne sais pas ce que c'est.
Bon.
On verra.
Oui.
J'ai une question,
il y a,
enfin,
je peux m'en dire,
il n'y a un nom,
c'est pas pour une.
En fait,
je ne vous reçois
que vous n'avez plus ça,
j'ai arrivé de perte.
Ah oui !
Alors,
perte,
tous les systèmes,
il y a très de bons suivants,
enfin,
toi,
avec du basting,
c'est moderne de l'enriage moderne,
voilà,
comme tout ça.
Alors,
on a bien pris,
mais le problème,
c'est que,
par rapport à ce problème,
hyper précis,
qui est de dire,
moi, je veux,
comment dire,
c'est vraiment,
trouver un élément,
enfin,
il faudrait que,
typiquement,
on a testé
perte
et les grands modèles de langage,
pour autre chose.
En fait,
l'idée qui était derrière,
justement,
on a peu de trucs négatifs.
Donc,
l'idée qui était derrière,
c'est de dire,
eh ben,
on va faire générer,
avec ces grands modèles de langage,
qui sont faits,
qui sont super bons en génération,
en fait,
de dire,
on va faire générer des choses.
Sauf que,
comment dire,
c'est,
pour l'instant,
enfin,
moi, on avait testé sur,
pas chaque GPT,
mais la version précédente,
qui était disponible en ligne,
machin, etc.
Bon,
pour dire,
on met un liste de propriétés,
d'éléments,
et,
fabrique-moi du texte,
en fait.
Donc,
on a fait ça.
Et le problème,
c'est incontrôlable.
Je m'explique.
On met Michelin,
en fait,
on met toute la liste
des propriétés du feu,
et on me dit,
bah,
voilà,
en fait,
et il m'a fait
quatre lignes
sur Michelin,
grande société française,
machin,
leader,
ici,
ce n'est pas un problème,
en fait.
Donc,
c'est le fait d'arriver à compte,
ce n'est pas un problème,
pour moi,
pour ces grands modèles de langage,
c'est de contrôler
ce qu'ils produisent.
Oui, oui, vas-y.
En fait,
je crois qu'une partie
intéressante de Berth,
c'est surtout en fait de récupérer
comment lui,
en pensant.
Oui, c'est que là,
comme les Warpers,
forcément,
le texte,
plus,
c'est qu'on avait dit
c'est qu'un moment de jour,
on fait le test.
Mais cette fois-ci,
pour l'aspect,
codale, justement.
Voilà.
Parce que là,
finalement,
en fonction de nos règles,
soit du WorldWake,
c'est beau.
Là, on s'était dit,
quand on aura le temps.
Oui, je sais que c'est ça, en fait.
C'est de dire,
on va faire du Berth,
pour coder.
Mais ça serait une utilisation
pour coder.
Moi, je sais que c'était par rapport...
Non, non, c'est parce que
je sais que c'est beaucoup utilisé,
et qu'en fait,
actuellement,
on va être publié,
surtout dans le domaine du NLP,
et même...
Oui, oui, oui.
C'est très compliqué,
parce qu'il y a Berth,
en fait, et que ça...
Bah oui, ça avait plus de suite,
Attendez, je vais poser la question,
parce que vu que vous l'oubliez,
je me dis,
ça a été compliqué.
Sur cette partie-là,
on publique sur les partis,
vraiment,
et on a ça en ligne.
Épiquement là,
dans les partis du Monolabel,
donc on a un algorithme multilabel
qui faisait à la fois
le labeling,
la détection de qualifier,
et aussi la qualification.
Donc ils faisaient la totalité.
Ça veut dire,
à la fois,
finalement, ils faisaient,
à la fois,
la détection multilabel
et la réagression
qui est associée à la tonalité.
Donc ça,
ça a été une publication,
une thèse,
il y a pas mal de publications.
Et là,
sur le topique modeling,
là, typiquement,
là-dessus,
on n'a pas publié,
parce que,
sur le truc qui en prend
aujourd'hui,
on a publié
sur le topique modeling,
etc.
Mais effectivement,
sur ce...
mégalisme actuel,
on n'a pas publié.
Voilà.
Parce que là,
je trouve que...
Pour ça,
je publie viteux.
Mais pour dire,
non,
mais tout peut être amélioré,
parce que,
perte,
c'est apparu.
C'est qu'elle a dit,
perte.
Bon.
Mais on s'est interrogé,
mais après,
on est trop...
Ça suffit.
Voilà.
Donc,
effectivement,
en plus,
c'est à tout.
Avec Val,
vous aurez des problèmes
pour la différence du produit,
évidemment.
Mais là,
c'est...
Voilà,
mais c'est que pour le codage.
Enfin,
pour moi,
c'est remplacer le codage,
finalement.
Les tokens,
en fait,
tu dis moi.
C'est un autre technique
de codage,
qu'il utilise aussi
comme un autre technique
de codage.
J'ai une petite question
du genre
de côté ML,
plutôt,
une scrapping,
on n'avait pas trop parlé.
Ah bon, non.
Ça a été...
Non,
c'est pas grave.
Si vous n'avez pas du connaissance,
c'est pas grave.
Non, non, mais...
Pas de problème.
Quand vous achetez le produit,
vous écoutez vos scrapping,
vous aurez encore plus les vannes,
en quelque sorte.
Ah bah,
de toute façon,
nous, quand on aspire,
on n'aspire pas
par vos produits.
D'accord.
On aspire la totalité
d'ici.
Ouais.
Tout.
Donc,
justement,
l'objectif,
c'est de récupérer aussi
des nouveaux produits.
Donc,
quand on aspire un site,
enfin, un site de pneus,
on aspire tout le contenu
d'un site de pneus.
Un site pour,
bah,
pour les...
comme on dit,
pour les huiles moteurs,
on n'y connaissait rien,
on n'avait pas de référentiel,
on a pris toutes les
segmentations
huiles moteurs,
etc.,
et on a tout aspiré.
Bon, évidemment,
à l'intérieur,
on s'aperçoit que c'est mal glacé,
dans les sites.
Tout est n'importe quoi.
Il y a aussi des huiles,
mais c'est une nourriture,
c'est Amazon.
Donc,
je ne sais pas
ce que ça faisait là,
mais bon,
il n'y a pas le...
comment dirais-je,
le dealer a dû mal ronger
son truc.
Bon,
c'est pas grave.
Mais donc,
non,
l'objectif,
c'est justement
ce qu'on vend aussi
à nos clients,
c'est le fait de détecter
des nouveaux produits
sans arrêt,
de nouvelles choses,
etc.
On a des alertings
par rapport
des nouveaux produits,
par rapport...
qu'ils sont plus aspirés.
Est-ce qu'il y a une liste
au quart en mécale,
ou...
Alors,
avant,
on a tous,
depuis l'origine,
dans stock tout,
alors avant,
on avait un centre serrat,
et maintenant,
c'est chez
un petit fournisseur,
parce qu'on s'est cloubifiés complètement,
c'est donc que c'est chez Amazon.
J'espère qu'ils ont bien vu
les références,
comme quoi,
chaque fois qu'on pose un truc chez Amazon,
c'est pas la propriété d'Amazon,
mais...
Bon,
là, pour l'instant,
on a fait vraiment au démarrage,
c'était que du truc classique,
SQL,
machin, etc.
Ensuite,
on a fait
des gros clusters
à doute,
machin,
puis là,
maintenant,
on a tout retransteré
chez...
Amazon.
Maintenant,
on lance un truc en réalité,
on fait attention,
c'est qu'ils seront turfournes.
Horsqu'un an.
On s'est ratés.
Ça fait 48 heures que ça tourne,
non,
pas ça,
on va attendre.
On a une alerte.
Oui ?
Ah bah,
là, pour l'instant,
justement,
l'objectif,
c'est
en fait, on est deux.
J'avais dit qu'on était très bestiaux.
Donc là,
quelque part,
la vision,
c'est
tous les ans.
On va calculer tout.
Voilà.
Donc c'est pas vraiment...
Parce qu'on compte,
là aussi,
dans le monde thématique,
il va pas y avoir
une révolution quoique.
En ce moment,
on parle beaucoup d'électriques,
machin, etc.
Donc il y a des nouveaux éléments,
des nouveaux problèmes,
mais bon,
on a dit,
pas vraiment de s'emmener.
Donc,
après,
on me dit que ça,
si vraiment,
il y a une alerte par rapport
à les gens qui disent,
bah non,
là,
c'est pour ça qu'on s'aviguerait.
Mais,
non,
on a résolu le problème
par...
J'ai plus de questions.
Il y a une chose
avant l'NJPD,
que le données qu'on se travait,
c'est, par contre,
quand on se travait,
après une minute de données,
qu'on ne peut pas utiliser
parce qu'on n'a pas le droit,
c'est qu'on reste assez donné qu'au...
Ah oui, oui.
Parce que,
comment dire,
quand on se trappe,
déjà,
quand on se trappe à site internet,
il n'y a pas d'information
particulière
sur...
sur la partie
des amnibus,
c'est-à-dire,
sur les blogs,
on nettoie tout.
C'est-à-dire que, quelque part,
tout est amnibus,
les noms, les machins,
c'est fou, en fait.
Les personnes qui parlent,
qui parlent,
c'est le cadet de l'office.
Donc,
on n'extrait que les fausses.
Ah, ça, par contre,
on a...
qu'est-ce qu'on a chez nous,
je vais le faire,
le légal,
et là,
non.
C'est pas possible.
Voilà.
Il dit non.
Après, il y a des sites,
je ne le ferais pas,
des sites aussi de commerce,
machin, etc.,
ou dans leur truc,
des sites à Paris,
j'en ai gagné un pour serre,
et ça va un peu bon.
Par rapport à ça,
on le fait de dire,
parce que,
globalement,
on a non.
Ce qu'on n'a pas le droit,
quelque part, c'est de dire,
j'espire,
et je revends exactement
ce que j'espire.
S'il n'y a pas de plus-value
par rapport à ce que j'espire,
là, c'est totalement,
c'est de là,
comme on dit,
c'est du vol.
Nous,
on n'en rend jamais,
qu'on bête.
Pour le moment,
on vend les produits,
matchés,
qualifiés, etc.,
avec plein d'informations
supplémentaires.
Les textes
que l'on y arrive,
des postes,
qu'on a reçu.
Que l'on y arrive,
le client,
on ne le voit jamais.
Oui, ce qu'il veut,
c'est les indicateurs.
Bon, après,
le client,
il se regarde,
machin,
il doit bien voir,
mais bon,
après, il voit le poste,
c'est vraiment aignisé
qu'il y a pas de liens
à remonter vers la personne
qui a,
alenne.
Ah ben, il se...
Il y a des termines d'automhte.
Vam.
...
Voilà.
Il détermine, effectivement,
le nombre d'automne
de plus-pertimente,
d'accord.
Oui.
Il y a d'autres.
Ah.
Bah oui, c'est un des d'autres.
Vous voyez quand même des petits apports.
Il a fait une thème.
Des petits apports.
Ah ben, ça c'est...
On va le voir.
Bon.
Ça c'est notre vision actuelle.
On va déjà voir
ce que ça va donner
sur ces fameux produits.
Puis on verra
l'évolution, effectivement.
Donc on refrape
où on est
pendant un topique modeling
pour dire est-ce qu'il y a une...
une évolution, etc.
Justement,
il y a ce fameux topique
dynamique, là.
Dernier.
Il a fait.
Voilà.
Mais pour l'instant,
on sait pas importement
on va intégrer ça
dans la classification,
parce que là,
quelque part,
un niveau élément,
très souvent,
c'est en remplacement d'un topique
qui s'éteint,
il y a des autres choses.
Bon.
Là, pour là,
c'est comme si
ce problème n'existait pas.
Voilà.
Pour l'instant,
on va déjà voir
si on a des éléments,
des cas qui arrivent comme ça.
Là, on pourra réfléchir.
Mais pour l'instant,
on va...
On est dans une note,
on va déjà essayer
d'appliquer
sur un carrière.
Donc,
sur un domaine
qu'on connaît,
pas du tout.
Et voir ce que ça donne.
Donc, c'est ça.
Déjà,
on sera déjà bien contents
de ce truc.
Parce que
sans obligation
de qualification,
ça, c'est génial.
En fait, quelque part,
c'est un truc
important.
Parce que dans le débénisation,
c'était plus...
Ah, les gens,
les gens qui étaient embauchés
chez nous,
ah, j'ai compris.
Qui l'avait visé,
donc,
à un moment,
il n'y avait qu'un seul personne.
Qui faisait que ça.
Bon, il y a d'autres choses,
parce qu'il est normalement
dégardé d'un modérateur.
Donc,
vous avez d'autres choses.
C'est sûr, mais il est lâché, etc.
Mais,
il était d'outilien,
il avait aussi
il avait qu'il maîtrise les langues
dans les six langues.
Donc,
voilà.
On était très
d'outilien.
Le petit péterage.
C'est là.
Là, c'est à moi.
C'est le skat.
C'est pas mal.
Putain, c'est l'heure d'arrêter.
C'est ça, c'est ça.
Merci.
Bon,
allez.
